{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6445,
     "status": "ok",
     "timestamp": 1661184531125,
     "user": {
      "displayName": "Jinzhen Wang",
      "userId": "15283478945620550865"
     },
     "user_tz": 240
    },
    "id": "C6DexQIzXn2p",
    "outputId": "d6f89a21-cd2a-4d17-a163-5e7381c6a7d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:06<00:00,  5.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/LANL_CompVisStudy/syncDarwin_local/models/DeepQA-modified/\")\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class IQANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IQANet, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.conv_featmap_ref = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_featmap_dis = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_featmap_err = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv_concat = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=128, kernel_size=1, padding=0, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.down_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.down_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.same = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.up_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128 + 128, out_channels=128, kernel_size=3, stride=2, padding=1,\n",
    "                               output_padding=1, dilation=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128 + 128, out_channels=128, kernel_size=3, stride=2, padding=1,\n",
    "                               output_padding=1, dilation=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.sens = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128 + 128, out_channels=1, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, r_img, d_img, err):\n",
    "        # r_img: N_batch x N_channel x Height x Width\n",
    "        featmap_ref = self.conv_featmap_ref(r_img)\n",
    "        featmap_dis = self.conv_featmap_dis(d_img)\n",
    "        featmap_err = self.conv_featmap_err(err)\n",
    "\n",
    "        featmap_concat = torch.cat((featmap_ref, featmap_dis, featmap_err), dim=1)\n",
    "        featmap = self.conv_concat(featmap_concat)\n",
    "\n",
    "        featmap_1 = self.down_1(featmap)\n",
    "        featmap_1_down = self.maxpool(featmap_1)\n",
    "\n",
    "        featmap_2 = self.down_2(featmap_1_down)\n",
    "        featmap_2_down = self.maxpool(featmap_2)\n",
    "\n",
    "        featmap_3 = self.same(featmap_2_down)\n",
    "        featmap_3 = torch.cat((featmap_3, featmap_2_down), dim=1)\n",
    "\n",
    "        featmap_4 = self.up_2(featmap_3)\n",
    "        featmap_4 = torch.cat((featmap_4, featmap_1_down), dim=1)\n",
    "\n",
    "        featmap_5 = self.up_1(featmap_4)\n",
    "        featmap_5 = torch.cat((featmap_5, featmap), dim=1)\n",
    "\n",
    "        sens = self.sens(featmap_5)\n",
    "\n",
    "        percept_err = torch.mul(sens, err)\n",
    "        pred_score = torch.mean(percept_err, dim=(2, 3))\n",
    "\n",
    "        # pred_score = self.fc(pred_score)\n",
    "\n",
    "        return pred_score, sens, percept_err\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample)\n",
    "\n",
    "def log_diff_fn(in_a, in_b, eps=0.1):\n",
    "    diff = 255 * (in_a - in_b)\n",
    "    log_diff = np.float32(np.log(diff ** 2 + eps))\n",
    "    log_max = np.float32(2 * np.log(255))\n",
    "    log_min = np.float32(np.log(eps))\n",
    "\n",
    "    log_diff_norm = (log_max - log_diff) / (log_max - log_min)\n",
    "\n",
    "    return log_diff_norm\n",
    "\n",
    "GPU_NUM = \"0\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_NUM\n",
    "# print(\"Using GPU %s\" % GPU_NUM)\n",
    "\n",
    "dirname = './Test'\n",
    "weight_file = 'FR_Sens_augment_best.pth'\n",
    "result_score_txt = 'output_deepQA.csv'\n",
    "\n",
    "model = IQANet().cuda()\n",
    "model.load_state_dict(torch.load(weight_file))\n",
    "model.eval()\n",
    "\n",
    "transforms = torchvision.transforms.Compose([ToTensor()])\n",
    "\n",
    "# filenames = os.listdir(dirname)\n",
    "# filenames.sort()\n",
    "filenames = []\n",
    "for field_name in [\"baryon_density\", \"dark_matter_density\", \"temperature\", \"velocity_x\"]:\n",
    "    for comp_name in [\"sz\", \"zfp\", \"mgard\"]:\n",
    "        filenames.extend(glob.glob(\"Test/{}-{}_config1.png\".format(field_name, comp_name)))\n",
    "        filenames.extend(glob.glob(\"Test/{}-{}_config2.png\".format(field_name, comp_name)))\n",
    "        filenames.extend(glob.glob(\"Test/{}-{}_config3.png\".format(field_name, comp_name)))\n",
    "\n",
    "# print(filenames)\n",
    "\n",
    "f = open(result_score_txt, 'w')\n",
    "f.write(\"dis_name,ref_name,score\\n\")\n",
    "for filename in tqdm(filenames):                  # Test/baryon_density-sz_config1.png\n",
    "    # d_img_name = os.path.join(dirname, filename)\n",
    "    d_img_name = os.path.join(filename)\n",
    "    ext = os.path.splitext(d_img_name)[-1]\n",
    "    if ext == '.png':\n",
    "        r_img_name = filename.split(\"/\")[1].split(\"-\")[0] + '.png'\n",
    "        r_img_name = os.path.join(dirname, 'Reference', r_img_name)\n",
    "        r_img = img.imread(r_img_name)\n",
    "\n",
    "        if np.max(r_img) > 1:\n",
    "            r_img = np.array(r_img).astype('float32') / 255\n",
    "        # r_img: H x W x C(=RGB) -> H x W (Grayscale) -> 1 x H x W\n",
    "        r_img = 0.2989 * r_img[:, :, 0] + 0.5870 * r_img[:, :, 1] + 0.1140 * r_img[:, :, 2]\n",
    "\n",
    "        d_img = img.imread(d_img_name)\n",
    "        if np.max(d_img) > 1:\n",
    "            d_img = np.array(d_img).astype('float32') / 255\n",
    "        # d_img: H x W x C(=RGB) -> H x W (Grayscale) -> 1 x H x W\n",
    "        d_img = 0.2989 * d_img[:, :, 0] + 0.5870 * d_img[:, :, 1] + 0.1140 * d_img[:, :, 2]\n",
    "\n",
    "        err = log_diff_fn(r_img, d_img)\n",
    "\n",
    "        r_img = r_img[None, :, :]\n",
    "        d_img = d_img[None, :, :]\n",
    "        err = err[None, :, :]\n",
    "\n",
    "        # r_img = transforms(r_img)\n",
    "        # r_img = torch.tensor(r_img.cuda()).unsqueeze(0)\n",
    "        r_img = transforms(r_img).cuda()\n",
    "        r_img = r_img.clone().detach().unsqueeze(0)\n",
    "\n",
    "        # d_img = transforms(d_img)\n",
    "        # d_img = torch.tensor(d_img.cuda()).unsqueeze(0)\n",
    "        d_img = transforms(d_img).cuda()\n",
    "        d_img = d_img.clone().detach().unsqueeze(0)\n",
    "\n",
    "        # err = transforms(err)\n",
    "        # err = torch.tensor(err.cuda()).unsqueeze(0)\n",
    "        err = transforms(err).cuda()\n",
    "        err = err.clone().detach().unsqueeze(0)\n",
    "\n",
    "        # Quality prediction\n",
    "        pred, sens, percept_err = model(r_img, d_img, err)\n",
    "\n",
    "        line = \"%s,%s,%f\\n\" % (filename.split(\"/\")[1], r_img_name.split(\"/\")[3], float(pred.item()))\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1661184493567,
     "user": {
      "displayName": "Jinzhen Wang",
      "userId": "15283478945620550865"
     },
     "user_tz": 240
    },
    "id": "YtFw4wUHHMLX"
   },
   "outputs": [],
   "source": [
    "# filenames = []\n",
    "# for field_name in [\"baryon_density\", \"dark_matter_density\", \"temperature\", \"velocity_x\"]:  #, \"dark_matter_density\", \"temperature\", \"velocity_x\n",
    "#     for comp_name in [\"sz\", \"zfp\", \"mgard\"]:\n",
    "#         filenames.extend(glob.glob(\"Test/{}-{}_config1.png\".format(field_name, comp_name)))\n",
    "#         filenames.extend(glob.glob(\"Test/{}-{}_config2.png\".format(field_name, comp_name)))\n",
    "#         filenames.extend(glob.glob(\"Test/{}-{}_config3.png\".format(field_name, comp_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1661184493567,
     "user": {
      "displayName": "Jinzhen Wang",
      "userId": "15283478945620550865"
     },
     "user_tz": 240
    },
    "id": "CAPnp4owRHK2"
   },
   "outputs": [],
   "source": [
    "# filenames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1661184558458,
     "user": {
      "displayName": "Jinzhen Wang",
      "userId": "15283478945620550865"
     },
     "user_tz": 240
    },
    "id": "joZ-VA2pTSqZ"
   },
   "outputs": [],
   "source": [
    "# cat output_deepQA.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpQhsJoIT_cf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXa0MpbQrkpCrX4cR6cFJF",
   "collapsed_sections": [],
   "mount_file_id": "1eRHmpeUK85GeGDs6EatY1x5xtcer9yQB",
   "name": "run_DeepQA.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
